{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import gc\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.utils.data import TensorDataset,  DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import optuna\n",
    "import os\n",
    "import random\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None) # 경고 off\n",
    "pd.options.display.float_format = '{:.5f}'.format\n",
    "optuna.logging.set_verbosity(optuna.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x206316323d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.1\n",
      "True\n",
      "1\n",
      "12.1\n",
      "학습을 진행하는 기기: cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.version.cuda)\n",
    "print('학습을 진행하는 기기:', torch.device('cuda:0' if torch.cuda.is_available() else 'cpu'))\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "torch.set_printoptions(precision=4, sci_mode=False)\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.load(\"train_UrineSCr & UrineSCr_dataset.pt\")\n",
    "valid_dataset = torch.load(\"valid_UrineSCr & UrineSCr_dataset.pt\")\n",
    "calibration_dataset = torch.load(\"calibration_UrineSCr & UrineSCr_dataset.pt\")\n",
    "test_dataset = torch.load(\"test_UrineSCr & UrineSCr_dataset.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = []\n",
    "dataset_names = [\"train\", \"valid\", \"calibration\", \"test\"]\n",
    "\n",
    "for name in dataset_names:\n",
    "    dataloader = DataLoader(eval(name + \"_dataset\"), batch_size=1, shuffle=True, drop_last=False)\n",
    "    dataloaders.append(dataloader)\n",
    "\n",
    "train_dataloader, valid_dataloader, calibration_dataloader, test_dataloader = dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_numeric shape: torch.Size([43984, 56, 58])\n",
      "X_presence shape: torch.Size([43984, 56, 83])\n",
      "Y_main shape: torch.Size([43984, 8, 56])\n",
      "Y_sub shape: torch.Size([43984, 4, 56])\n",
      "mask shape: torch.Size([43984, 56])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader.dataset:\n",
    "    X_numeric, X_presence, Y_main, Y_sub, mask = batch.tensors\n",
    "    print(\"X_numeric shape:\", X_numeric.shape)\n",
    "    print(\"X_presence shape:\", X_presence.shape)\n",
    "    print(\"Y_main shape:\", Y_main.shape)\n",
    "    print(\"Y_sub shape:\", Y_sub.shape)\n",
    "    print(\"mask shape:\", mask.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# overweight for positive weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet('train_UrineSCr & UrineSCr.parquet')\n",
    "valid = pd.read_parquet('valid_UrineSCr & UrineSCr.parquet')\n",
    "train_id = pd.read_parquet('train_id.parquet')\n",
    "valid_id = pd.read_parquet('valid_id.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weights_main = []\n",
    "pos_weights_main.append(sum(train['GT_presence_6'] == 0) / sum(train['GT_presence_6'] == 1))\n",
    "pos_weights_main.append(sum(train['GT_presence_12'] == 0) / sum(train['GT_presence_12'] == 1))\n",
    "pos_weights_main.append(sum(train['GT_presence_18'] == 0) / sum(train['GT_presence_18'] == 1))\n",
    "pos_weights_main.append(sum(train['GT_presence_24'] == 0) / sum(train['GT_presence_24'] == 1))\n",
    "pos_weights_main.append(sum(train['GT_presence_30'] == 0) / sum(train['GT_presence_30'] == 1))\n",
    "pos_weights_main.append(sum(train['GT_presence_36'] == 0) / sum(train['GT_presence_36'] == 1))\n",
    "pos_weights_main.append(sum(train['GT_presence_42'] == 0) / sum(train['GT_presence_42'] == 1))\n",
    "pos_weights_main.append(sum(train['GT_presence_48'] == 0) / sum(train['GT_presence_48'] == 1))\n",
    "pos_weights_main = torch.Tensor(pos_weights_main)\n",
    "pos_weights_main_train = pos_weights_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weights_main = []\n",
    "pos_weights_main.append(sum(valid['GT_presence_6'] == 0) / sum(valid['GT_presence_6'] == 1))\n",
    "pos_weights_main.append(sum(valid['GT_presence_12'] == 0) / sum(valid['GT_presence_12'] == 1))\n",
    "pos_weights_main.append(sum(valid['GT_presence_18'] == 0) / sum(valid['GT_presence_18'] == 1))\n",
    "pos_weights_main.append(sum(valid['GT_presence_24'] == 0) / sum(valid['GT_presence_24'] == 1))\n",
    "pos_weights_main.append(sum(valid['GT_presence_30'] == 0) / sum(valid['GT_presence_30'] == 1))\n",
    "pos_weights_main.append(sum(valid['GT_presence_36'] == 0) / sum(valid['GT_presence_36'] == 1))\n",
    "pos_weights_main.append(sum(valid['GT_presence_42'] == 0) / sum(valid['GT_presence_42'] == 1))\n",
    "pos_weights_main.append(sum(valid['GT_presence_48'] == 0) / sum(valid['GT_presence_48'] == 1))\n",
    "pos_weights_main = torch.Tensor(pos_weights_main)\n",
    "pos_weights_main_valid = pos_weights_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weights_sub = []\n",
    "pos_weights_sub.append((len(train_id)- sum(train_id['RRT'] == 1)) / sum(train_id['RRT'] == 1))\n",
    "pos_weights_sub.append(sum(train['GT_stage_3'] == 0) / sum(train['GT_stage_3'] == 1))\n",
    "pos_weights_sub.append(sum(train['GT_stage_2'] == 0) / sum(train['GT_stage_2'] == 1))\n",
    "pos_weights_sub.append(sum(train['GT_stage_1'] == 0) / sum(train['GT_stage_1'] == 1))\n",
    "pos_weights_sub = torch.Tensor(pos_weights_sub)\n",
    "pos_weights_sub_train = pos_weights_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weights_sub = []\n",
    "pos_weights_sub.append((len(valid_id)- sum(valid_id['RRT'] == 1)) / sum(valid_id['RRT'] == 1))\n",
    "pos_weights_sub.append(sum(valid['GT_stage_3'] == 0) / sum(valid['GT_stage_3'] == 1))\n",
    "pos_weights_sub.append(sum(valid['GT_stage_2'] == 0) / sum(valid['GT_stage_2'] == 1))\n",
    "pos_weights_sub.append(sum(valid['GT_stage_1'] == 0) / sum(valid['GT_stage_1'] == 1))\n",
    "pos_weights_sub = torch.Tensor(pos_weights_sub)\n",
    "pos_weights_sub_valid = pos_weights_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weights_sub = []\n",
    "pos_weights_sub.append(sum(valid['GT_stage_3D'] == 0) / sum(valid['GT_stage_3D'] == 1))\n",
    "pos_weights_sub.append(sum(valid['GT_stage_3'] == 0) / sum(valid['GT_stage_3'] == 1))\n",
    "pos_weights_sub.append(sum(valid['GT_stage_2'] == 0) / sum(valid['GT_stage_2'] == 1))\n",
    "pos_weights_sub.append(sum(valid['GT_stage_1'] == 0) / sum(valid['GT_stage_1'] == 1))\n",
    "pos_weights_sub = torch.Tensor(pos_weights_sub)\n",
    "pos_weights_sub_valid = pos_weights_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience, loss_names, verbose=False, delta=0, path='Earlystopping.pt'):\n",
    "        self.patience = patience\n",
    "        self.loss_names = loss_names\n",
    "        self.verbose = verbose\n",
    "        self.counters = 0\n",
    "        self.best_scores = {loss_name: None for loss_name in loss_names}\n",
    "        self.early_stop = False\n",
    "        self.loss_min = {loss_name: np.Inf for loss_name in loss_names}\n",
    "        self.loss_min_past = {loss_name: np.Inf for loss_name in loss_names}\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "\n",
    "    def __call__(self, losses, model, epoch, num_epochs, avg_train_loss, avg_train_main_loss, avg_train_sub_loss,avg_valid_loss, avg_valid_main_loss,avg_valid_sub_loss):\n",
    "        all_losses_improved = all(loss_value < self.loss_min[loss_name] for loss_name, loss_value in losses.items())\n",
    "        \n",
    "        if all_losses_improved:\n",
    "            for loss_name, loss_value in losses.items():\n",
    "                if self.best_scores[loss_name] is None:\n",
    "                    self.best_scores[loss_name] = loss_value\n",
    "                    self.loss_min[loss_name] = loss_value\n",
    "                    self.save_checkpoint(losses, model)\n",
    "                elif loss_value < self.best_scores[loss_name]:\n",
    "                    self.best_scores[loss_name] = loss_value\n",
    "                    self.loss_min_past[loss_name] = self.loss_min[loss_name]\n",
    "                    self.loss_min[loss_name] = loss_value\n",
    "                    self.save_checkpoint(losses, model)\n",
    "                    self.counters = 0\n",
    "            if self.verbose:\n",
    "                print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {avg_train_loss:.4f} - main Loss: {avg_train_main_loss:.4f} - sub Loss: {avg_train_sub_loss:.4f} - Valid Loss: {avg_valid_loss:.4f} - main Loss: {avg_valid_main_loss:.4f} - sub Loss: {avg_valid_sub_loss:.4f}\")\n",
    "        else:\n",
    "            self.counters += 1\n",
    "            if self.counters >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "    def save_checkpoint(self, losses, model):\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCGrad():\n",
    "    def __init__(self, optimizer, reduction='mean'):\n",
    "        self._optim, self._reduction = optimizer, reduction\n",
    "        return\n",
    "\n",
    "    @property\n",
    "    def optimizer(self):\n",
    "        return self._optim\n",
    "\n",
    "    def zero_grad(self):\n",
    "        '''\n",
    "        clear the gradient of the parameters\n",
    "        '''\n",
    "\n",
    "        return self._optim.zero_grad(set_to_none=True)\n",
    "\n",
    "    def step(self):\n",
    "        '''\n",
    "        update the parameters with the gradient\n",
    "        '''\n",
    "\n",
    "        return self._optim.step()\n",
    "\n",
    "    def pc_backward(self, objectives):\n",
    "        '''\n",
    "        calculate the gradient of the parameters\n",
    "\n",
    "        input:\n",
    "        - objectives: a list of objectives\n",
    "        '''\n",
    "        grads, shapes, has_grads = self._pack_grad(objectives)\n",
    "        pc_grad = self._project_conflicting(grads, has_grads)\n",
    "        pc_grad = self._unflatten_grad(pc_grad, shapes[0])\n",
    "        self._set_grad(pc_grad)\n",
    "        \n",
    "        return\n",
    "\n",
    "    def _project_conflicting(self, grads, has_grads, shapes=None):\n",
    "\n",
    "        shared = torch.stack(has_grads).prod(0).bool()\n",
    "        pc_grad  = copy.deepcopy(grads)\n",
    "        for g_i in pc_grad:\n",
    "            random.shuffle(grads)\n",
    "            for g_j in grads:\n",
    "                g_i_g_j = torch.dot(g_i, g_j)\n",
    "                if g_i_g_j < 0:\n",
    "                    g_i -= (g_i_g_j) * g_j / (g_j.norm()**2)\n",
    "\n",
    "        merged_grad = torch.zeros_like(grads[0])\n",
    "\n",
    "        if self._reduction:\n",
    "            merged_grad[shared] = torch.stack([g[shared]\n",
    "                                        for g in pc_grad]).mean(dim=0)\n",
    "        elif self._reduction == 'sum':\n",
    "            merged_grad[shared] = torch.stack([g[shared]\n",
    "                                        for g in pc_grad]).sum(dim=0)\n",
    "            \n",
    "        else: exit('invalid reduction method')\n",
    "\n",
    "        merged_grad[~shared] = torch.stack([g[~shared]\n",
    "                                            for g in pc_grad]).sum(dim=0)\n",
    "\n",
    "        return merged_grad.clone().detach()\n",
    "\n",
    "    def _set_grad(self, grads):\n",
    "\n",
    "        '''\n",
    "        set the modified gradients to the network\n",
    "        '''\n",
    "        idx = 0\n",
    "        for group in self._optim.param_groups:\n",
    "            for p in group['params']:\n",
    "                # if p.grad is None: continue\n",
    "                p.grad = grads[idx]\n",
    "                idx += 1\n",
    "\n",
    "        return\n",
    "\n",
    "    def _pack_grad(self, objectives):\n",
    "        '''\n",
    "        pack the gradient of the parameters of the network for each objective\n",
    "        \n",
    "        output:\n",
    "        - grad: a list of the gradient of the parameters\n",
    "        - shape: a list of the shape of the parameters\n",
    "        - has_grad: a list of mask represent whether the parameter has gradient\n",
    "        '''\n",
    "\n",
    "        grads, shapes, has_grads = [], [], []\n",
    "\n",
    "        self._optim.zero_grad(set_to_none=True)\n",
    "        objectives[0].backward(retain_graph=True)\n",
    "        grad, shape, has_grad = self._retrieve_grad()\n",
    "        grads.append(self._flatten_grad(grad, shape))\n",
    "        has_grads.append(self._flatten_grad(has_grad, shape))\n",
    "        shapes.append(shape)\n",
    "    \n",
    "        self._optim.zero_grad(set_to_none=True)\n",
    "        objectives[1].backward(retain_graph=False)\n",
    "        grad, shape, has_grad = self._retrieve_grad()\n",
    "        grads.append(self._flatten_grad(grad, shape))\n",
    "        has_grads.append(self._flatten_grad(has_grad, shape))\n",
    "        shapes.append(shape)\n",
    "\n",
    "        return grads, shapes, has_grads\n",
    "\n",
    "    def _unflatten_grad(self, grads, shapes):\n",
    "\n",
    "        unflatten_grad, idx = [], 0\n",
    "        for shape in shapes:\n",
    "            length = np.prod(shape)\n",
    "            unflatten_grad.append(Variable(grads[idx:(idx + length)].view(shape).clone(), requires_grad = False))\n",
    "            idx += length\n",
    "        \n",
    "        return unflatten_grad\n",
    "\n",
    "    def _flatten_grad(self, grads, shapes):\n",
    "\n",
    "        flatten_grad = torch.cat([g.flatten() for g in grads])\n",
    "        return flatten_grad.clone().detach()\n",
    "\n",
    "    def _retrieve_grad(self):\n",
    "        '''\n",
    "        get the gradient of the parameters of the network with specific \n",
    "        objective\n",
    "        \n",
    "        output:\n",
    "        - grad: a list of the gradient of the parameters\n",
    "        - shape: a list of the shape of the parameters\n",
    "        - has_grad: a list of mask represent whether the parameter has gradient\n",
    "        '''\n",
    "        grad, shape, has_grad = [], [], []\n",
    "        for group in self._optim.param_groups:\n",
    "            for p in group['params']:\n",
    "                # if p.grad is None: continue\n",
    "                # tackle the multi-head scenario\n",
    "                \n",
    "                if p.grad is None:\n",
    "                    shape.append(p.shape)\n",
    "                    grad.append(torch.zeros_like(p).to(p.device))\n",
    "                    has_grad.append(torch.zeros_like(p).to(p.device))\n",
    "                    continue\n",
    "\n",
    "                shape.append(p.grad.shape)\n",
    "                grad.append(p.grad.clone())\n",
    "                has_grad.append(torch.ones_like(p).to(p.device))\n",
    "    \n",
    "        return grad, shape, has_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingModule(nn.Module):\n",
    "    def __init__(self, embedding_size, embedding_num_layers, activation_type, LN, seq_len, numeric_input_size, presence_input_size, CB):\n",
    "        super(EmbeddingModule, self).__init__()\n",
    "\n",
    "        self.CB = CB\n",
    "        self.LN = LN\n",
    "        self.num_layers = embedding_num_layers\n",
    "\n",
    "        # 활성화 함수 매핑\n",
    "        activation_functions = {\n",
    "            'ReLU': nn.ReLU(),\n",
    "            'LeakyReLU': nn.LeakyReLU(),\n",
    "            'Tanh': nn.Tanh(),\n",
    "            'ELU': nn.ELU(),\n",
    "            'SELU': nn.SELU(),\n",
    "            'CELU': nn.CELU(),\n",
    "            'GELU': nn.GELU(),\n",
    "        }\n",
    "\n",
    "        # 선택된 활성화 함수\n",
    "        activation_function = activation_functions.get(activation_type, nn.ReLU())  # 기본값은 ReLU\n",
    "\n",
    "        self.embedding_numeric = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(numeric_input_size if i == 0 else embedding_size, embedding_size),\n",
    "                activation_function,\n",
    "            ) for i in range(self.num_layers)\n",
    "        ])\n",
    "\n",
    "        self.embedding_presence = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(presence_input_size if i == 0 else embedding_size, embedding_size),\n",
    "                activation_function,\n",
    "            ) for i in range(self.num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.LN = nn.LayerNorm(normalized_shape=(seq_len, 2 * embedding_size if CB else embedding_size), eps=1e-05)\n",
    "\n",
    "    def forward(self, x_numeric, x_presence):\n",
    "        \n",
    "        for i in range(len(self.embedding_numeric)):\n",
    "            x_numeric = self.embedding_numeric[i](x_numeric)\n",
    "            x_presence = self.embedding_presence[i](x_presence)\n",
    "\n",
    "        if self.CB :\n",
    "            embedded = torch.cat([x_numeric, x_presence], dim=2)\n",
    "\n",
    "        else :\n",
    "            embedded = x_numeric + x_presence\n",
    "\n",
    "        if self.LN:\n",
    "            embedded = self.LN(embedded)\n",
    "\n",
    "        return embedded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentModule(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding_size, recurrent_num_layers, recurrent_type, highway_network,CB):\n",
    "        super(RecurrentModule, self).__init__()\n",
    "\n",
    "        self.embedding_size = embedding_size\n",
    "        self.num_layers = recurrent_num_layers\n",
    "        self.highway_network = highway_network\n",
    "\n",
    "        # 리커런트 모듈 매핑\n",
    "        recurrent_modules = {\n",
    "            'RNN': nn.RNN,\n",
    "            'GRU': nn.GRU,\n",
    "            'LSTM': nn.LSTM\n",
    "        }\n",
    "\n",
    "        # 선택된 리커런트 모듈\n",
    "        recurrent_module = recurrent_modules.get(recurrent_type, nn.RNN)  # 기본값은 RNN\n",
    "\n",
    "        input_size =  2 * self.embedding_size if CB else self.embedding_size\n",
    "\n",
    "        self.recurrent_layers = nn.ModuleList([\n",
    "            recurrent_module(input_size if i == 0 else hidden_size, hidden_size, 1, batch_first=True) for i in range(self.num_layers)\n",
    "        ])\n",
    "\n",
    "        if self.highway_network:\n",
    "            # Create a list to hold the highway layers dynamically (except the final layer)\n",
    "            self.highway_layers = nn.ModuleList([\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(hidden_size, hidden_size),\n",
    "                    nn.Linear(hidden_size, hidden_size)\n",
    "                )\n",
    "                for _ in range(self.num_layers - 1)\n",
    "            ])\n",
    "\n",
    "        self.fc_main = nn.Linear(hidden_size, 8)\n",
    "        self.fc_sub = nn.Linear(hidden_size, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = x\n",
    "\n",
    "        if (self.num_layers != 1):\n",
    "            if self.highway_network:\n",
    "                for i in range(self.num_layers - 1):\n",
    "                    out, _ = self.recurrent_layers[i](out)\n",
    "\n",
    "                    # Apply the highway network\n",
    "                    h = out\n",
    "                    t = torch.sigmoid(self.highway_layers[i][0](h))\n",
    "                    transformed = torch.relu(self.highway_layers[i][1](h))\n",
    "                    out = t * transformed + (1 - t) * h\n",
    "            else: \n",
    "                for i in range(self.num_layers - 1):\n",
    "                    out, _ = self.recurrent_layers[i](out)\n",
    "        else:\n",
    "            out, _ = self.recurrent_layers[-1](out)\n",
    "\n",
    "        out_main = self.fc_main(out)\n",
    "        out_sub = self.fc_sub(out)\n",
    "\n",
    "        out_main = out_main.transpose(1,2).contiguous()\n",
    "        out_sub = out_sub.transpose(1,2).contiguous()\n",
    "\n",
    "        return out_main, out_sub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AKIPredictionModel(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding_size, recurrent_num_layers, embedding_num_layers, activation_type, recurrent_type, seq_len, LN, highway_network, numeric_input_size, presence_input_size, CB):\n",
    "        super(AKIPredictionModel, self).__init__()\n",
    "\n",
    "        self.embedding_module = EmbeddingModule(embedding_size, embedding_num_layers, activation_type, LN, seq_len, numeric_input_size, presence_input_size, CB)\n",
    "        self.recurrent_module = RecurrentModule(hidden_size, embedding_size, recurrent_num_layers, recurrent_type, highway_network, CB)\n",
    "\n",
    "    def forward(self, x_numeric, x_presence):\n",
    "\n",
    "        embedded = self.embedding_module(x_numeric, x_presence)\n",
    "        out_main, out_sub = self.recurrent_module(embedded)\n",
    "\n",
    "        return out_main, out_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBCELoss(nn.Module):\n",
    "    def __init__(self, pos_weight):\n",
    "        super(CustomBCELoss, self).__init__()\n",
    "        self.pos_weight = pos_weight\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        # 각 클래스에 대한 긍정 가중치 적용\n",
    "        eps = 1e-12\n",
    "        input_clamped = torch.clamp(input, min=eps, max= (1 - eps))\n",
    "        loss = - (self.pos_weight * target * torch.log(input_clamped) + (1 - target) * torch.log(1 - input_clamped))\n",
    "        \n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdf(df):\n",
    "    df, _ = torch.cummax(df, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_CDFo(model, train_dataloader, valid_dataloader, learning_rate, num_epochs, lr_decay_factor, lr_decay_steps, LD, path, batchsize) :\n",
    "\n",
    "    criterion_main_train = [CustomBCELoss(pos_weight=pos_weight) for pos_weight in pos_weights_main_train]\n",
    "    criterion_sub_train = [CustomBCELoss(pos_weight=pos_weight) for pos_weight in pos_weights_sub_train]\n",
    "\n",
    "    criterion_main_valid = [CustomBCELoss(pos_weight=pos_weight) for pos_weight in pos_weights_main_valid]\n",
    "    criterion_sub_valid = [CustomBCELoss(pos_weight=pos_weight) for pos_weight in pos_weights_sub_valid]\n",
    "\n",
    "    losses = {\n",
    "    'valid_loss': 0,\n",
    "    'main_loss': 0,\n",
    "    'sub_loss': 0\n",
    "    }\n",
    "\n",
    "    loss_names = ['valid_loss', 'main_loss', 'sub_loss']\n",
    "    early_stopping = EarlyStopping(patience = lr_decay_steps * 2, path=path, loss_names=loss_names, verbose = False)\n",
    "\n",
    "    optimizer = PCGrad(optim.Adam(model.parameters(), lr=learning_rate))\n",
    "    scheduler = ExponentialLR(optimizer.optimizer, gamma=lr_decay_factor)\n",
    "\n",
    "    step = 0\n",
    "\n",
    "    for epoch in range(num_epochs):      \n",
    "\n",
    "        train_batch_dataloader = DataLoader(train_dataloader.dataset[0], batch_size = batchsize, shuffle = True, drop_last = False, pin_memory = True, num_workers = 4)\n",
    "\n",
    "        for data in train_batch_dataloader:\n",
    "\n",
    "            step += 1\n",
    "            model.train()\n",
    "\n",
    "            inputs_numeric, inputs_presence, targets_main, targets_sub, mask = [d.to(device) for d in data]\n",
    "            out_main, out_sub = model(inputs_numeric, inputs_presence)\n",
    "\n",
    "            train_loss = 0.0\n",
    "            train_main_loss = 0.0\n",
    "            train_sub_loss = 0.0 \n",
    "\n",
    "            out_main = F.sigmoid(out_main)\n",
    "            out_sub = F.sigmoid(out_sub)\n",
    "\n",
    "            out_main = cdf(out_main)\n",
    "            out_sub = cdf(out_sub)\n",
    "\n",
    "            train_main_loss += sum(criterion(out_main[:, j], targets_main[:, j]) for j, criterion in enumerate(criterion_main_train))\n",
    "            train_sub_loss += sum(criterion(out_sub[:, j], targets_sub[:, j]) for j, criterion in enumerate(criterion_sub_train))     \n",
    "            \n",
    "            train_loss += (train_main_loss + train_sub_loss).item()\n",
    "            optimizer.pc_backward([train_main_loss,train_sub_loss])\n",
    "            optimizer.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "            \n",
    "                model.eval()\n",
    "                valid_loss = 0.0\n",
    "                valid_main_loss = 0.0\n",
    "                valid_sub_loss = 0.0\n",
    "\n",
    "                for data in valid_dataloader.dataset:\n",
    "                \n",
    "                    inputs_numeric, inputs_presence, targets_main, targets_sub, mask = [d.to(device) for d in data.tensors]\n",
    "                    out_main, out_sub = model(inputs_numeric, inputs_presence)\n",
    "\n",
    "                    out_main = F.sigmoid(out_main)\n",
    "                    out_sub = F.sigmoid(out_sub)\n",
    "\n",
    "                    out_main = cdf(out_main)\n",
    "                    out_sub = cdf(out_sub)\n",
    "\n",
    "                    valid_main_loss += sum(criterion(out_main[:, j], targets_main[:, j]) for j, criterion in enumerate(criterion_main_valid))\n",
    "                    valid_sub_loss += sum(criterion(out_sub[:, j], targets_sub[:, j]) for j, criterion in enumerate(criterion_sub_valid))\n",
    "\n",
    "                valid_loss += (valid_main_loss + valid_sub_loss).item()\n",
    "\n",
    "                losses['valid_loss'] = valid_loss\n",
    "                losses['main_loss'] = valid_main_loss.item()\n",
    "                losses['sub_loss'] = valid_sub_loss.item()\n",
    "\n",
    "                early_stopping(losses, model, epoch, num_epochs, train_loss, train_main_loss, train_sub_loss, valid_loss, valid_main_loss, valid_sub_loss)\n",
    "\n",
    "                wandb.log({'step': step,\"train:\":train_loss, \"main_train:\":train_main_loss,\"sub_train:\":train_sub_loss, \"val:\":valid_loss, \"main_val:\": valid_main_loss, \"sub_val:\": valid_sub_loss})\n",
    "\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "                if early_stopping.early_stop:\n",
    "\n",
    "                    valid_loss = 0.0\n",
    "                    valid_main_loss = 0.0\n",
    "                    valid_sub_loss = 0.0\n",
    "     \n",
    "                    model.load_state_dict(torch.load(path))\n",
    "                    out_main, out_sub = model(inputs_numeric, inputs_presence)\n",
    "                    \n",
    "                    out_main = F.sigmoid(out_main)\n",
    "                    out_sub = F.sigmoid(out_sub)\n",
    "                    \n",
    "                    out_main = cdf(out_main)\n",
    "                    out_sub = cdf(out_sub)\n",
    "\n",
    "                    valid_main_loss += sum(criterion(out_main[:, j], targets_main[:, j]) for j, criterion in enumerate(criterion_main_valid))\n",
    "                    valid_sub_loss += sum(criterion(out_sub[:, j], targets_sub[:, j]) for j, criterion in enumerate(criterion_sub_valid))\n",
    "                    valid_loss += (valid_main_loss + valid_sub_loss).item()\n",
    "                    break\n",
    "            \n",
    "                elif (((step % lr_decay_steps) == 0) & (LD)) :\n",
    "                    scheduler.step()  \n",
    "                    continue\n",
    "\n",
    "            if early_stopping.early_stop : break\n",
    "\n",
    "        if early_stopping.early_stop : break\n",
    "\n",
    "    return model, valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_CDFx(model, train_dataloader, valid_dataloader, learning_rate, num_epochs, lr_decay_factor, lr_decay_steps, LD, path, batchsize) :\n",
    "\n",
    "    criterion_main_train = [nn.BCEWithLogitsLoss(pos_weight=pos_weight) for pos_weight in pos_weights_main_train]\n",
    "    criterion_sub_train = [nn.BCEWithLogitsLoss(pos_weight=pos_weight) for pos_weight in pos_weights_sub_train]\n",
    "\n",
    "    criterion_main_valid = [nn.BCEWithLogitsLoss(pos_weight=pos_weight) for pos_weight in pos_weights_main_valid]\n",
    "    criterion_sub_valid = [nn.BCEWithLogitsLoss(pos_weight=pos_weight) for pos_weight in pos_weights_sub_valid]\n",
    "\n",
    "    losses = {\n",
    "    'valid_loss': 0,\n",
    "    'main_loss': 0,\n",
    "    'sub_loss': 0\n",
    "    }\n",
    "\n",
    "    loss_names = ['valid_loss', 'main_loss', 'sub_loss']\n",
    "    early_stopping = EarlyStopping(patience = lr_decay_steps * 2, path=path, loss_names=loss_names, verbose = False)\n",
    "\n",
    "    optimizer = PCGrad(optim.Adam(model.parameters(), lr=learning_rate))\n",
    "    scheduler = ExponentialLR(optimizer.optimizer, gamma=lr_decay_factor)\n",
    "\n",
    "    step = 0\n",
    "\n",
    "    for epoch in range(num_epochs):      \n",
    "\n",
    "        train_batch_dataloader = DataLoader(train_dataloader.dataset[0], batch_size = batchsize, shuffle = True, drop_last = False, pin_memory = True, num_workers = 4)\n",
    "\n",
    "        for data in train_batch_dataloader:\n",
    "\n",
    "            step += 1\n",
    "            model.train()\n",
    "\n",
    "            inputs_numeric, inputs_presence, targets_main, targets_sub, mask = [d.to(device) for d in data]\n",
    "            out_main, out_sub = model(inputs_numeric, inputs_presence)\n",
    "\n",
    "            train_loss = 0.0\n",
    "            train_main_loss = 0.0\n",
    "            train_sub_loss = 0.0 \n",
    "\n",
    "            train_main_loss += sum(criterion(out_main[:, j], targets_main[:, j]) for j, criterion in enumerate(criterion_main_train))\n",
    "            train_sub_loss += sum(criterion(out_sub[:, j], targets_sub[:, j]) for j, criterion in enumerate(criterion_sub_train))     \n",
    "            \n",
    "            train_loss += (train_main_loss + train_sub_loss).item()\n",
    "            optimizer.pc_backward([train_main_loss,train_sub_loss])\n",
    "            optimizer.step()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "            \n",
    "                model.eval()\n",
    "\n",
    "                for data in valid_dataloader.dataset:\n",
    "                \n",
    "                    valid_loss = 0.0\n",
    "                    valid_main_loss = 0.0\n",
    "                    valid_sub_loss = 0.0\n",
    "\n",
    "                    inputs_numeric, inputs_presence, targets_main, targets_sub, mask = [d.to(device) for d in data.tensors]\n",
    "                    out_main, out_sub = model(inputs_numeric, inputs_presence)\n",
    "\n",
    "                    valid_main_loss += sum(criterion(out_main[:, j], targets_main[:, j]) for j, criterion in enumerate(criterion_main_valid))\n",
    "                    valid_sub_loss += sum(criterion(out_sub[:, j], targets_sub[:, j]) for j, criterion in enumerate(criterion_sub_valid))\n",
    "\n",
    "                valid_loss += (valid_main_loss + valid_sub_loss).item()\n",
    "\n",
    "                losses['valid_loss'] = valid_loss\n",
    "                losses['main_loss'] = valid_main_loss.item()\n",
    "                losses['sub_loss'] = valid_sub_loss.item()\n",
    "\n",
    "                early_stopping(losses, model, epoch, num_epochs, train_loss, train_main_loss, train_sub_loss, valid_loss, valid_main_loss, valid_sub_loss)\n",
    "\n",
    "                wandb.log({'step': step,\"train:\":train_loss, \"main_train:\":train_main_loss,\"sub_train:\":train_sub_loss, \"val:\":valid_loss, \"main_val:\": valid_main_loss, \"sub_val:\": valid_sub_loss})\n",
    "\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "                if early_stopping.early_stop:\n",
    "\n",
    "                    valid_loss = 0.0\n",
    "                    valid_main_loss = 0.0\n",
    "                    valid_sub_loss = 0.0\n",
    "        \n",
    "                    model.load_state_dict(torch.load(path))\n",
    "                    out_main, out_sub = model(inputs_numeric, inputs_presence)\n",
    "                    valid_main_loss += sum(criterion(out_main[:, j], targets_main[:, j]) for j, criterion in enumerate(criterion_main_valid))\n",
    "                    valid_sub_loss += sum(criterion(out_sub[:, j], targets_sub[:, j]) for j, criterion in enumerate(criterion_sub_valid))\n",
    "                    valid_loss += (valid_main_loss + valid_sub_loss).item()\n",
    "                    break\n",
    "            \n",
    "                elif (((step % lr_decay_steps) == 0) & (LD)) :\n",
    "                    scheduler.step()  \n",
    "                    continue\n",
    "\n",
    "            if early_stopping.early_stop : break\n",
    "\n",
    "        if early_stopping.early_stop : break    \n",
    "\n",
    "    return model, valid_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    numeric_input_size = len(train_dataloader.dataset[0].tensors[0][0][0])\n",
    "    presence_input_size = len(train_dataloader.dataset[0].tensors[1][0][0])\n",
    "\n",
    "    seq_len = 56\n",
    "    num_epochs = 1000000\n",
    "\n",
    "    # Define hyperparameters to be optimized\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 50 , 200, step = 50)\n",
    "    embedding_size = trial.suggest_int(\"embedding_size\", 25, 100, step = 25)\n",
    "\n",
    "    recurrent_num_layers = trial.suggest_int(\"recurrent_num_layers\", 1, 5)  # 1부터 3까지의 정수 값 중 하나 선택\n",
    "    embedding_num_layers = trial.suggest_int(\"embedding_num_layers\", 1, 5)  # 1부터 3까지의 정수 값 중 하나 선택\n",
    "\n",
    "    CB = trial.suggest_categorical(\"CB\", [0 ,1]) # 0 : sum , 1 : concat\n",
    "    recurrent_type = trial.suggest_categorical(\"recurrent_type\", ['LSTM','RNN','GRU'])\n",
    "    activation_type = trial.suggest_categorical(\"activation_type\", ['ReLU','LeakyReLU','Tanh','ELU','SELU','CELU','GELU'])\n",
    "    \n",
    "    batchsize = trial.suggest_categorical(\"Batchsize\", [64, 128, 256, 512])\n",
    "    learning_rate = trial.suggest_categorical(\"learning_rate\", [1e-4, 1e-3, 1e-2])\n",
    "    lr_decay_steps = trial.suggest_categorical(\"lr_decay_steps\", [800, 400, 200, 100])\n",
    "    lr_decay_factor = trial.suggest_categorical(\"lr_decay_factor\", [0.7, 0.8, 0.85, 0.9, 0.95])\n",
    " \n",
    "    HN = trial.suggest_categorical(\"highway_network\", [0, 1])\n",
    "    LD = trial.suggest_categorical(\"LD\", [0, 1])\n",
    "    LN = trial.suggest_categorical(\"LN\", [0, 1])\n",
    "    CDF = trial.suggest_categorical(\"CDF\", [0, 1])\n",
    "\n",
    "    wandb.init(\n",
    "        project='towards better clinical applicability', name=f'A-{trial.number}', reinit=True,\n",
    "        config={\n",
    "        'hidden_size':hidden_size,\n",
    "        'embedding_size':embedding_size,\n",
    "        'recurrent_num_layers': recurrent_num_layers,\n",
    "        'embedding_num_layers':embedding_num_layers,\n",
    "        'Combinbation':CB,\n",
    "        'recurrent_type': recurrent_type,\n",
    "        'activation_type': activation_type,\n",
    "        \"batch_size\":batchsize,\n",
    "        \"learning_rate\":learning_rate,\n",
    "        \"lr_decay_factor\":lr_decay_factor,\n",
    "        \"lr_decay_steps\":lr_decay_steps,\n",
    "        \"highway_network\":HN,\n",
    "        \"learning_decay\":LD,\n",
    "        \"Layer_Normalization\":LN,\n",
    "        \"CDF\":CDF,\n",
    "    })\n",
    "    \n",
    "    # Create and train the model with the specified hyperparameters\n",
    "    model = AKIPredictionModel(hidden_size, embedding_size, recurrent_num_layers, embedding_num_layers, activation_type, recurrent_type, seq_len, LN, HN, numeric_input_size, presence_input_size, CB).to(device)\n",
    "    path = f\"trial_{trial.number}_model.pt\"\n",
    "\n",
    "    # Train the model using your `train` function\n",
    "\n",
    "    if CDF : target_loss = train_CDFo(model, train_dataloader, valid_dataloader, learning_rate, num_epochs, lr_decay_factor, lr_decay_steps, LD, path, batchsize)\n",
    "    else : target_loss = train_CDFx(model, train_dataloader, valid_dataloader, learning_rate, num_epochs, lr_decay_factor, lr_decay_steps, LD, path, batchsize)\n",
    "\n",
    "    return target_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 01:48:13,845] A new study created in RDB with name: no-name-def1c71c-9b43-48d4-98f5-2406b58304f2\n",
      "[I 2024-02-26 04:18:32,237] Trial 0 finished with value: 0.8709253072738647 and parameters: {'hidden_size': 50, 'embedding_size': 100, 'recurrent_num_layers': 5, 'embedding_num_layers': 4, 'CB': 0, 'recurrent_type': 'RNN', 'activation_type': 'ReLU', 'Batchsize': 128, 'learning_rate': 0.0001, 'lr_decay_steps': 800, 'lr_decay_factor': 0.95, 'highway_network': 0, 'LD': 0, 'LN': 0, 'CDF': 0}. Best is trial 0 with value: 0.8709253072738647.\n",
      "[I 2024-02-26 04:29:13,915] Trial 1 finished with value: 1.0596877336502075 and parameters: {'hidden_size': 100, 'embedding_size': 50, 'recurrent_num_layers': 5, 'embedding_num_layers': 2, 'CB': 1, 'recurrent_type': 'RNN', 'activation_type': 'ReLU', 'Batchsize': 128, 'learning_rate': 0.001, 'lr_decay_steps': 100, 'lr_decay_factor': 0.95, 'highway_network': 0, 'LD': 0, 'LN': 0, 'CDF': 1}. Best is trial 0 with value: 0.8709253072738647.\n",
      "[I 2024-02-26 04:49:50,669] Trial 2 finished with value: 0.994528591632843 and parameters: {'hidden_size': 200, 'embedding_size': 50, 'recurrent_num_layers': 4, 'embedding_num_layers': 3, 'CB': 1, 'recurrent_type': 'RNN', 'activation_type': 'SELU', 'Batchsize': 64, 'learning_rate': 0.001, 'lr_decay_steps': 200, 'lr_decay_factor': 0.85, 'highway_network': 0, 'LD': 1, 'LN': 0, 'CDF': 0}. Best is trial 0 with value: 0.8709253072738647.\n",
      "[I 2024-02-26 05:29:47,381] Trial 3 finished with value: 0.9662379622459412 and parameters: {'hidden_size': 150, 'embedding_size': 75, 'recurrent_num_layers': 2, 'embedding_num_layers': 1, 'CB': 1, 'recurrent_type': 'LSTM', 'activation_type': 'SELU', 'Batchsize': 64, 'learning_rate': 0.01, 'lr_decay_steps': 800, 'lr_decay_factor': 0.8, 'highway_network': 1, 'LD': 1, 'LN': 1, 'CDF': 0}. Best is trial 0 with value: 0.8709253072738647.\n",
      "[I 2024-02-26 05:35:04,516] Trial 4 finished with value: 1.0331369638442993 and parameters: {'hidden_size': 100, 'embedding_size': 50, 'recurrent_num_layers': 2, 'embedding_num_layers': 4, 'CB': 1, 'recurrent_type': 'RNN', 'activation_type': 'Tanh', 'Batchsize': 256, 'learning_rate': 0.001, 'lr_decay_steps': 100, 'lr_decay_factor': 0.8, 'highway_network': 1, 'LD': 0, 'LN': 0, 'CDF': 0}. Best is trial 0 with value: 0.8709253072738647.\n",
      "[I 2024-02-26 05:43:52,533] Trial 5 finished with value: 1.1326091289520264 and parameters: {'hidden_size': 50, 'embedding_size': 25, 'recurrent_num_layers': 3, 'embedding_num_layers': 1, 'CB': 1, 'recurrent_type': 'GRU', 'activation_type': 'GELU', 'Batchsize': 64, 'learning_rate': 0.01, 'lr_decay_steps': 100, 'lr_decay_factor': 0.9, 'highway_network': 1, 'LD': 1, 'LN': 1, 'CDF': 1}. Best is trial 0 with value: 0.8709253072738647.\n",
      "[I 2024-02-26 05:55:44,384] Trial 6 finished with value: 0.8885115385055542 and parameters: {'hidden_size': 100, 'embedding_size': 25, 'recurrent_num_layers': 1, 'embedding_num_layers': 2, 'CB': 0, 'recurrent_type': 'GRU', 'activation_type': 'ReLU', 'Batchsize': 512, 'learning_rate': 0.001, 'lr_decay_steps': 100, 'lr_decay_factor': 0.85, 'highway_network': 1, 'LD': 0, 'LN': 1, 'CDF': 0}. Best is trial 0 with value: 0.8709253072738647.\n",
      "[I 2024-02-26 06:03:56,697] Trial 7 finished with value: 1.1476149559020996 and parameters: {'hidden_size': 200, 'embedding_size': 75, 'recurrent_num_layers': 1, 'embedding_num_layers': 2, 'CB': 0, 'recurrent_type': 'RNN', 'activation_type': 'Tanh', 'Batchsize': 512, 'learning_rate': 0.01, 'lr_decay_steps': 400, 'lr_decay_factor': 0.85, 'highway_network': 0, 'LD': 0, 'LN': 1, 'CDF': 1}. Best is trial 0 with value: 0.8709253072738647.\n",
      "[I 2024-02-26 06:53:02,349] Trial 8 finished with value: 0.8210203647613525 and parameters: {'hidden_size': 50, 'embedding_size': 75, 'recurrent_num_layers': 5, 'embedding_num_layers': 3, 'CB': 0, 'recurrent_type': 'GRU', 'activation_type': 'GELU', 'Batchsize': 128, 'learning_rate': 0.001, 'lr_decay_steps': 400, 'lr_decay_factor': 0.9, 'highway_network': 0, 'LD': 1, 'LN': 1, 'CDF': 0}. Best is trial 8 with value: 0.8210203647613525.\n",
      "[I 2024-02-26 07:00:09,590] Trial 9 finished with value: 0.864595890045166 and parameters: {'hidden_size': 150, 'embedding_size': 75, 'recurrent_num_layers': 2, 'embedding_num_layers': 2, 'CB': 1, 'recurrent_type': 'GRU', 'activation_type': 'SELU', 'Batchsize': 512, 'learning_rate': 0.01, 'lr_decay_steps': 100, 'lr_decay_factor': 0.9, 'highway_network': 0, 'LD': 0, 'LN': 0, 'CDF': 0}. Best is trial 8 with value: 0.8210203647613525.\n",
      "[I 2024-02-26 07:38:57,658] Trial 10 finished with value: 1.6951470375061035 and parameters: {'hidden_size': 50, 'embedding_size': 100, 'recurrent_num_layers': 4, 'embedding_num_layers': 3, 'CB': 0, 'recurrent_type': 'LSTM', 'activation_type': 'GELU', 'Batchsize': 128, 'learning_rate': 0.0001, 'lr_decay_steps': 400, 'lr_decay_factor': 0.7, 'highway_network': 0, 'LD': 1, 'LN': 1, 'CDF': 1}. Best is trial 8 with value: 0.8210203647613525.\n",
      "[I 2024-02-26 08:02:57,315] Trial 11 finished with value: 0.7775343656539917 and parameters: {'hidden_size': 150, 'embedding_size': 75, 'recurrent_num_layers': 3, 'embedding_num_layers': 5, 'CB': 0, 'recurrent_type': 'GRU', 'activation_type': 'ELU', 'Batchsize': 512, 'learning_rate': 0.01, 'lr_decay_steps': 400, 'lr_decay_factor': 0.9, 'highway_network': 0, 'LD': 1, 'LN': 0, 'CDF': 0}. Best is trial 11 with value: 0.7775343656539917.\n",
      "[I 2024-02-26 08:31:49,913] Trial 12 finished with value: 0.7954477667808533 and parameters: {'hidden_size': 150, 'embedding_size': 75, 'recurrent_num_layers': 4, 'embedding_num_layers': 5, 'CB': 0, 'recurrent_type': 'GRU', 'activation_type': 'ELU', 'Batchsize': 256, 'learning_rate': 0.01, 'lr_decay_steps': 400, 'lr_decay_factor': 0.9, 'highway_network': 0, 'LD': 1, 'LN': 1, 'CDF': 0}. Best is trial 11 with value: 0.7775343656539917.\n",
      "[I 2024-02-26 09:02:47,603] Trial 13 finished with value: 0.8007491827011108 and parameters: {'hidden_size': 150, 'embedding_size': 100, 'recurrent_num_layers': 3, 'embedding_num_layers': 5, 'CB': 0, 'recurrent_type': 'GRU', 'activation_type': 'ELU', 'Batchsize': 256, 'learning_rate': 0.01, 'lr_decay_steps': 400, 'lr_decay_factor': 0.9, 'highway_network': 0, 'LD': 1, 'LN': 0, 'CDF': 0}. Best is trial 11 with value: 0.7775343656539917.\n",
      "[I 2024-02-26 09:34:59,324] Trial 14 finished with value: 0.8748142719268799 and parameters: {'hidden_size': 150, 'embedding_size': 75, 'recurrent_num_layers': 4, 'embedding_num_layers': 5, 'CB': 0, 'recurrent_type': 'GRU', 'activation_type': 'ELU', 'Batchsize': 256, 'learning_rate': 0.01, 'lr_decay_steps': 400, 'lr_decay_factor': 0.9, 'highway_network': 0, 'LD': 1, 'LN': 0, 'CDF': 0}. Best is trial 11 with value: 0.7775343656539917.\n",
      "[I 2024-02-26 09:50:26,186] Trial 15 finished with value: 0.8900296688079834 and parameters: {'hidden_size': 200, 'embedding_size': 50, 'recurrent_num_layers': 3, 'embedding_num_layers': 5, 'CB': 0, 'recurrent_type': 'GRU', 'activation_type': 'ELU', 'Batchsize': 256, 'learning_rate': 0.01, 'lr_decay_steps': 200, 'lr_decay_factor': 0.7, 'highway_network': 0, 'LD': 1, 'LN': 1, 'CDF': 0}. Best is trial 11 with value: 0.7775343656539917.\n",
      "[I 2024-02-26 11:33:57,392] Trial 16 finished with value: 1.0528626441955566 and parameters: {'hidden_size': 150, 'embedding_size': 100, 'recurrent_num_layers': 4, 'embedding_num_layers': 4, 'CB': 0, 'recurrent_type': 'LSTM', 'activation_type': 'CELU', 'Batchsize': 512, 'learning_rate': 0.0001, 'lr_decay_steps': 400, 'lr_decay_factor': 0.9, 'highway_network': 0, 'LD': 1, 'LN': 0, 'CDF': 0}. Best is trial 11 with value: 0.7775343656539917.\n",
      "[I 2024-02-26 11:57:26,862] Trial 17 finished with value: 0.7845995426177979 and parameters: {'hidden_size': 100, 'embedding_size': 75, 'recurrent_num_layers': 4, 'embedding_num_layers': 5, 'CB': 0, 'recurrent_type': 'GRU', 'activation_type': 'LeakyReLU', 'Batchsize': 512, 'learning_rate': 0.01, 'lr_decay_steps': 400, 'lr_decay_factor': 0.9, 'highway_network': 0, 'LD': 1, 'LN': 1, 'CDF': 0}. Best is trial 11 with value: 0.7775343656539917.\n",
      "[I 2024-02-26 12:14:05,219] Trial 18 finished with value: 0.7607285976409912 and parameters: {'hidden_size': 100, 'embedding_size': 50, 'recurrent_num_layers': 3, 'embedding_num_layers': 4, 'CB': 0, 'recurrent_type': 'GRU', 'activation_type': 'LeakyReLU', 'Batchsize': 512, 'learning_rate': 0.01, 'lr_decay_steps': 400, 'lr_decay_factor': 0.9, 'highway_network': 1, 'LD': 1, 'LN': 0, 'CDF': 1}. Best is trial 18 with value: 0.7607285976409912.\n",
      "[I 2024-02-26 12:28:15,967] Trial 19 finished with value: 0.7835279107093811 and parameters: {'hidden_size': 100, 'embedding_size': 25, 'recurrent_num_layers': 2, 'embedding_num_layers': 4, 'CB': 0, 'recurrent_type': 'GRU', 'activation_type': 'LeakyReLU', 'Batchsize': 512, 'learning_rate': 0.01, 'lr_decay_steps': 800, 'lr_decay_factor': 0.8, 'highway_network': 1, 'LD': 1, 'LN': 0, 'CDF': 1}. Best is trial 18 with value: 0.7607285976409912.\n",
      "[I 2024-02-26 12:59:37,489] Trial 20 finished with value: 1.5868444442749023 and parameters: {'hidden_size': 100, 'embedding_size': 50, 'recurrent_num_layers': 3, 'embedding_num_layers': 4, 'CB': 0, 'recurrent_type': 'LSTM', 'activation_type': 'LeakyReLU', 'Batchsize': 512, 'learning_rate': 0.0001, 'lr_decay_steps': 200, 'lr_decay_factor': 0.7, 'highway_network': 1, 'LD': 1, 'LN': 0, 'CDF': 1}. Best is trial 18 with value: 0.7607285976409912.\n",
      "[I 2024-02-26 13:10:25,689] Trial 21 finished with value: 0.8313661813735962 and parameters: {'hidden_size': 100, 'embedding_size': 25, 'recurrent_num_layers': 2, 'embedding_num_layers': 4, 'CB': 0, 'recurrent_type': 'GRU', 'activation_type': 'LeakyReLU', 'Batchsize': 512, 'learning_rate': 0.01, 'lr_decay_steps': 800, 'lr_decay_factor': 0.8, 'highway_network': 1, 'LD': 1, 'LN': 0, 'CDF': 1}. Best is trial 18 with value: 0.7607285976409912.\n",
      "[I 2024-02-26 13:29:08,481] Trial 22 finished with value: 0.7872738838195801 and parameters: {'hidden_size': 100, 'embedding_size': 25, 'recurrent_num_layers': 3, 'embedding_num_layers': 4, 'CB': 0, 'recurrent_type': 'GRU', 'activation_type': 'LeakyReLU', 'Batchsize': 512, 'learning_rate': 0.01, 'lr_decay_steps': 800, 'lr_decay_factor': 0.8, 'highway_network': 1, 'LD': 1, 'LN': 0, 'CDF': 1}. Best is trial 18 with value: 0.7607285976409912.\n",
      "[I 2024-02-26 13:40:01,073] Trial 23 finished with value: 0.8350819945335388 and parameters: {'hidden_size': 100, 'embedding_size': 25, 'recurrent_num_layers': 2, 'embedding_num_layers': 3, 'CB': 0, 'recurrent_type': 'GRU', 'activation_type': 'LeakyReLU', 'Batchsize': 512, 'learning_rate': 0.01, 'lr_decay_steps': 800, 'lr_decay_factor': 0.8, 'highway_network': 1, 'LD': 1, 'LN': 0, 'CDF': 1}. Best is trial 18 with value: 0.7607285976409912.\n",
      "[I 2024-02-26 13:59:19,986] Trial 24 finished with value: 0.7933673858642578 and parameters: {'hidden_size': 150, 'embedding_size': 50, 'recurrent_num_layers': 1, 'embedding_num_layers': 5, 'CB': 0, 'recurrent_type': 'GRU', 'activation_type': 'CELU', 'Batchsize': 512, 'learning_rate': 0.01, 'lr_decay_steps': 800, 'lr_decay_factor': 0.95, 'highway_network': 1, 'LD': 1, 'LN': 0, 'CDF': 1}. Best is trial 18 with value: 0.7607285976409912.\n",
      "[I 2024-02-26 14:09:33,668] Trial 25 finished with value: 0.7898995280265808 and parameters: {'hidden_size': 100, 'embedding_size': 25, 'recurrent_num_layers': 2, 'embedding_num_layers': 4, 'CB': 0, 'recurrent_type': 'GRU', 'activation_type': 'LeakyReLU', 'Batchsize': 512, 'learning_rate': 0.01, 'lr_decay_steps': 400, 'lr_decay_factor': 0.8, 'highway_network': 1, 'LD': 1, 'LN': 0, 'CDF': 1}. Best is trial 18 with value: 0.7607285976409912.\n",
      "[I 2024-02-26 14:25:13,513] Trial 26 finished with value: 0.7603350877761841 and parameters: {'hidden_size': 50, 'embedding_size': 50, 'recurrent_num_layers': 3, 'embedding_num_layers': 4, 'CB': 0, 'recurrent_type': 'GRU', 'activation_type': 'LeakyReLU', 'Batchsize': 512, 'learning_rate': 0.01, 'lr_decay_steps': 400, 'lr_decay_factor': 0.9, 'highway_network': 1, 'LD': 1, 'LN': 0, 'CDF': 1}. Best is trial 26 with value: 0.7603350877761841.\n",
      "[I 2024-02-26 14:47:34,002] Trial 27 finished with value: 0.7639325857162476 and parameters: {'hidden_size': 50, 'embedding_size': 50, 'recurrent_num_layers': 3, 'embedding_num_layers': 5, 'CB': 0, 'recurrent_type': 'GRU', 'activation_type': 'ELU', 'Batchsize': 512, 'learning_rate': 0.01, 'lr_decay_steps': 400, 'lr_decay_factor': 0.9, 'highway_network': 1, 'LD': 1, 'LN': 0, 'CDF': 1}. Best is trial 26 with value: 0.7603350877761841.\n",
      "[I 2024-02-26 15:49:32,088] Trial 28 finished with value: 1.3192028999328613 and parameters: {'hidden_size': 50, 'embedding_size': 50, 'recurrent_num_layers': 3, 'embedding_num_layers': 4, 'CB': 0, 'recurrent_type': 'LSTM', 'activation_type': 'LeakyReLU', 'Batchsize': 512, 'learning_rate': 0.0001, 'lr_decay_steps': 400, 'lr_decay_factor': 0.9, 'highway_network': 1, 'LD': 1, 'LN': 0, 'CDF': 1}. Best is trial 26 with value: 0.7603350877761841.\n",
      "[I 2024-02-26 16:04:17,774] Trial 29 finished with value: 0.9978514313697815 and parameters: {'hidden_size': 50, 'embedding_size': 50, 'recurrent_num_layers': 3, 'embedding_num_layers': 4, 'CB': 0, 'recurrent_type': 'GRU', 'activation_type': 'CELU', 'Batchsize': 64, 'learning_rate': 0.01, 'lr_decay_steps': 400, 'lr_decay_factor': 0.9, 'highway_network': 1, 'LD': 0, 'LN': 0, 'CDF': 1}. Best is trial 26 with value: 0.7603350877761841.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'hidden_size': 50, 'embedding_size': 50, 'recurrent_num_layers': 3, 'embedding_num_layers': 4, 'CB': 0, 'recurrent_type': 'GRU', 'activation_type': 'LeakyReLU', 'Batchsize': 512, 'learning_rate': 0.01, 'lr_decay_steps': 400, 'lr_decay_factor': 0.9, 'highway_network': 1, 'LD': 1, 'LN': 0, 'CDF': 1}\n",
      "Best Validation Loss: 0.7603350877761841\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Create an Optuna study and optimize the objective function\n",
    "    db_url = \"sqlite:///DAHS_study.db\"\n",
    "    study = optuna.create_study(direction=\"minimize\", storage = db_url)\n",
    "    study.optimize(objective, n_trials = 30)\n",
    "\n",
    "    # Get the best hyperparameters and corresponding loss\n",
    "    best_params = study.best_params\n",
    "    best_loss = study.best_value\n",
    "\n",
    "    print(\"Best Hyperparameters:\", best_params)\n",
    "    print(\"Best Validation Loss:\", best_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 50  # Replace with the desired hidden size\n",
    "num_layers = 3  # Replace with the desired number of layers\n",
    "seq_len = 56\n",
    "embedding_size = 50\n",
    "highway_network = 1\n",
    "Embedding_num_layers = 4\n",
    "Recurrent_module = 'GRU'\n",
    "Embedding_module = 'LeakyReLU'\n",
    "learning_rate = 0.01\n",
    "lr_decay_factor = 0.9\n",
    "lr_decay_steps = 400\n",
    "batchsize = 512\n",
    "patience = lr_decay_steps * 2\n",
    "LN = 0\n",
    "CB = 0\n",
    "LD = 1\n",
    "CDF = 1\n",
    "num_epochs = 10000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,dataloader):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    criterion =  [nn.BCELoss()]\n",
    "\n",
    "    main_datasets_6h = []\n",
    "    main_datasets_12h = []\n",
    "    main_datasets_18h = []\n",
    "    main_datasets_24h = []\n",
    "    main_datasets_30h = []\n",
    "    main_datasets_36h = []\n",
    "    main_datasets_42h = []\n",
    "    main_datasets_48h = []\n",
    "\n",
    "    sub_datasets_1 = []\n",
    "    sub_datasets_2 = []\n",
    "    sub_datasets_3 = []\n",
    "    sub_datasets_3D = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        test_loss = 0.0\n",
    "      \n",
    "        for data in dataloader.dataset:\n",
    "                \n",
    "            inputs_numeric, inputs_presence, targets_main, targets_sub, mask = [d.to(device) for d in data.tensors]\n",
    "            \n",
    "            out_main, out_sub = model(inputs_numeric, inputs_presence)\n",
    "\n",
    "            test_main_loss = 0.0\n",
    "            test_sub_loss = 0.0  \n",
    "\n",
    "            out_main = F.sigmoid(out_main)\n",
    "            out_sub = F.sigmoid(out_sub)    \n",
    "\n",
    "            out_main = cdf(out_main)\n",
    "            out_sub = cdf(out_sub)\n",
    "            \n",
    "            for i in range(mask.shape[0]):\n",
    "\n",
    "                length = (mask[i,:] == 0).sum()\n",
    "                test_main_loss += sum(criterion(out_main[i, j, :length], targets_main[i, j, :length]) for j, criterion in enumerate(criterion))\n",
    "                test_sub_loss += sum(criterion(out_sub[i, j, :length], targets_sub[i, j, :length]) for j, criterion in enumerate(criterion))\n",
    "\n",
    "            test_loss += (test_main_loss + test_sub_loss).item()\n",
    "\n",
    "            i = (mask[0,:] == 0).sum()\n",
    "\n",
    "            dataset = TensorDataset(out_main[:,0,:i],out_main[:,1,:i],out_main[:,2,:i],out_main[:,3,:i],out_main[:,4,:i],out_main[:,5,:i],out_main[:,6,:i],out_main[:,7,:i],\n",
    "                                    out_sub[:,3,:i],out_sub[:,2,:i],out_sub[:,1,:i],out_sub[:,0,:i],\n",
    "                                    targets_main[:,0,:i],targets_main[:,1,:i],targets_main[:,2,:i],targets_main[:,3,:i],targets_main[:,4,:i],targets_main[:,5,:i],targets_main[:,6,:i],targets_main[:,7,:i],\n",
    "                                    targets_sub[:,3,:i],targets_sub[:,2,:i],targets_sub[:,1,:i],targets_sub[:,0,:i])\n",
    "                                    \n",
    "            dataloader = DataLoader(dataset, batch_size=1, shuffle=False, drop_last=False)\n",
    "\n",
    "            for out_main_6h,out_main_12h,out_main_18h,out_main_24h,out_main_30h,out_main_36h,out_main_42h,out_main_48h,out_sub_1,out_sub_2,out_sub_3,out_sub_3D,targets_main_6h,targets_main_12h,targets_main_18h,targets_main_24h,targets_main_30h,targets_main_36h,targets_main_42h,targets_main_48h,targets_sub_1,targets_sub_2,targets_sub_3,targets_sub_3D in dataloader:\n",
    "                \n",
    "                main_dataset_6h = TensorDataset(out_main_6h, targets_main_6h)\n",
    "                main_dataset_12h = TensorDataset(out_main_12h, targets_main_12h)\n",
    "                main_dataset_18h = TensorDataset(out_main_18h, targets_main_18h)\n",
    "                main_dataset_24h = TensorDataset(out_main_24h, targets_main_24h)\n",
    "                main_dataset_30h = TensorDataset(out_main_30h, targets_main_30h)\n",
    "                main_dataset_36h = TensorDataset(out_main_36h, targets_main_36h)\n",
    "                main_dataset_42h = TensorDataset(out_main_42h, targets_main_42h)\n",
    "                main_dataset_48h = TensorDataset(out_main_48h, targets_main_48h)\n",
    "\n",
    "                main_datasets_6h.append(main_dataset_6h)\n",
    "                main_datasets_12h.append(main_dataset_12h)\n",
    "                main_datasets_18h.append(main_dataset_18h)\n",
    "                main_datasets_24h.append(main_dataset_24h)\n",
    "                main_datasets_30h.append(main_dataset_30h)\n",
    "                main_datasets_36h.append(main_dataset_36h)\n",
    "                main_datasets_42h.append(main_dataset_42h)\n",
    "                main_datasets_48h.append(main_dataset_48h)\n",
    "\n",
    "                sub_dataset_1 = TensorDataset(out_sub_1, targets_sub_1)\n",
    "                sub_dataset_2 = TensorDataset(out_sub_2, targets_sub_2)\n",
    "                sub_dataset_3 = TensorDataset(out_sub_3, targets_sub_3)\n",
    "                sub_dataset_3D = TensorDataset(out_sub_3D, targets_sub_3D)\n",
    "\n",
    "                sub_datasets_1.append(sub_dataset_1)\n",
    "                sub_datasets_2.append(sub_dataset_2)\n",
    "                sub_datasets_3.append(sub_dataset_3)\n",
    "                sub_datasets_3D.append(sub_dataset_3D)               \n",
    "\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "    main_datasets = [main_datasets_6h, main_datasets_12h, main_datasets_18h, main_datasets_24h,main_datasets_30h, main_datasets_36h, main_datasets_42h, main_datasets_48h]\n",
    "    sub_datasets = [sub_datasets_1, sub_datasets_2, sub_datasets_3, sub_datasets_3D]\n",
    "    \n",
    "    return main_datasets, sub_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_numeric shape: torch.Size([3, 56, 58])\n",
      "X_presence shape: torch.Size([3, 56, 83])\n",
      "Y_main shape: torch.Size([3, 8, 56])\n",
      "Y_sub shape: torch.Size([3, 4, 56])\n",
      "mask shape: torch.Size([3, 56])\n",
      "X_numeric shape: torch.Size([13, 56, 58])\n",
      "X_presence shape: torch.Size([13, 56, 83])\n",
      "Y_main shape: torch.Size([13, 8, 56])\n",
      "Y_sub shape: torch.Size([13, 4, 56])\n",
      "mask shape: torch.Size([13, 56])\n",
      "X_numeric shape: torch.Size([16, 56, 58])\n",
      "X_presence shape: torch.Size([16, 56, 83])\n",
      "Y_main shape: torch.Size([16, 8, 56])\n",
      "Y_sub shape: torch.Size([16, 4, 56])\n",
      "mask shape: torch.Size([16, 56])\n",
      "X_numeric shape: torch.Size([15, 56, 58])\n",
      "X_presence shape: torch.Size([15, 56, 83])\n",
      "Y_main shape: torch.Size([15, 8, 56])\n",
      "Y_sub shape: torch.Size([15, 4, 56])\n",
      "mask shape: torch.Size([15, 56])\n",
      "X_numeric shape: torch.Size([805, 56, 58])\n",
      "X_presence shape: torch.Size([805, 56, 83])\n",
      "Y_main shape: torch.Size([805, 8, 56])\n",
      "Y_sub shape: torch.Size([805, 4, 56])\n",
      "mask shape: torch.Size([805, 56])\n",
      "X_numeric shape: torch.Size([539, 56, 58])\n",
      "X_presence shape: torch.Size([539, 56, 83])\n",
      "Y_main shape: torch.Size([539, 8, 56])\n",
      "Y_sub shape: torch.Size([539, 4, 56])\n",
      "mask shape: torch.Size([539, 56])\n",
      "X_numeric shape: torch.Size([433, 56, 58])\n",
      "X_presence shape: torch.Size([433, 56, 83])\n",
      "Y_main shape: torch.Size([433, 8, 56])\n",
      "Y_sub shape: torch.Size([433, 4, 56])\n",
      "mask shape: torch.Size([433, 56])\n",
      "X_numeric shape: torch.Size([535, 56, 58])\n",
      "X_presence shape: torch.Size([535, 56, 83])\n",
      "Y_main shape: torch.Size([535, 8, 56])\n",
      "Y_sub shape: torch.Size([535, 4, 56])\n",
      "mask shape: torch.Size([535, 56])\n",
      "X_numeric shape: torch.Size([443, 56, 58])\n",
      "X_presence shape: torch.Size([443, 56, 83])\n",
      "Y_main shape: torch.Size([443, 8, 56])\n",
      "Y_sub shape: torch.Size([443, 4, 56])\n",
      "mask shape: torch.Size([443, 56])\n",
      "X_numeric shape: torch.Size([282, 56, 58])\n",
      "X_presence shape: torch.Size([282, 56, 83])\n",
      "Y_main shape: torch.Size([282, 8, 56])\n",
      "Y_sub shape: torch.Size([282, 4, 56])\n",
      "mask shape: torch.Size([282, 56])\n",
      "X_numeric shape: torch.Size([209, 56, 58])\n",
      "X_presence shape: torch.Size([209, 56, 83])\n",
      "Y_main shape: torch.Size([209, 8, 56])\n",
      "Y_sub shape: torch.Size([209, 4, 56])\n",
      "mask shape: torch.Size([209, 56])\n",
      "X_numeric shape: torch.Size([270, 56, 58])\n",
      "X_presence shape: torch.Size([270, 56, 83])\n",
      "Y_main shape: torch.Size([270, 8, 56])\n",
      "Y_sub shape: torch.Size([270, 4, 56])\n",
      "mask shape: torch.Size([270, 56])\n",
      "X_numeric shape: torch.Size([228, 56, 58])\n",
      "X_presence shape: torch.Size([228, 56, 83])\n",
      "Y_main shape: torch.Size([228, 8, 56])\n",
      "Y_sub shape: torch.Size([228, 4, 56])\n",
      "mask shape: torch.Size([228, 56])\n",
      "X_numeric shape: torch.Size([128, 56, 58])\n",
      "X_presence shape: torch.Size([128, 56, 83])\n",
      "Y_main shape: torch.Size([128, 8, 56])\n",
      "Y_sub shape: torch.Size([128, 4, 56])\n",
      "mask shape: torch.Size([128, 56])\n",
      "X_numeric shape: torch.Size([132, 56, 58])\n",
      "X_presence shape: torch.Size([132, 56, 83])\n",
      "Y_main shape: torch.Size([132, 8, 56])\n",
      "Y_sub shape: torch.Size([132, 4, 56])\n",
      "mask shape: torch.Size([132, 56])\n",
      "X_numeric shape: torch.Size([156, 56, 58])\n",
      "X_presence shape: torch.Size([156, 56, 83])\n",
      "Y_main shape: torch.Size([156, 8, 56])\n",
      "Y_sub shape: torch.Size([156, 4, 56])\n",
      "mask shape: torch.Size([156, 56])\n",
      "X_numeric shape: torch.Size([122, 56, 58])\n",
      "X_presence shape: torch.Size([122, 56, 83])\n",
      "Y_main shape: torch.Size([122, 8, 56])\n",
      "Y_sub shape: torch.Size([122, 4, 56])\n",
      "mask shape: torch.Size([122, 56])\n",
      "X_numeric shape: torch.Size([87, 56, 58])\n",
      "X_presence shape: torch.Size([87, 56, 83])\n",
      "Y_main shape: torch.Size([87, 8, 56])\n",
      "Y_sub shape: torch.Size([87, 4, 56])\n",
      "mask shape: torch.Size([87, 56])\n",
      "X_numeric shape: torch.Size([87, 56, 58])\n",
      "X_presence shape: torch.Size([87, 56, 83])\n",
      "Y_main shape: torch.Size([87, 8, 56])\n",
      "Y_sub shape: torch.Size([87, 4, 56])\n",
      "mask shape: torch.Size([87, 56])\n",
      "X_numeric shape: torch.Size([74, 56, 58])\n",
      "X_presence shape: torch.Size([74, 56, 83])\n",
      "Y_main shape: torch.Size([74, 8, 56])\n",
      "Y_sub shape: torch.Size([74, 4, 56])\n",
      "mask shape: torch.Size([74, 56])\n",
      "X_numeric shape: torch.Size([93, 56, 58])\n",
      "X_presence shape: torch.Size([93, 56, 83])\n",
      "Y_main shape: torch.Size([93, 8, 56])\n",
      "Y_sub shape: torch.Size([93, 4, 56])\n",
      "mask shape: torch.Size([93, 56])\n",
      "X_numeric shape: torch.Size([46, 56, 58])\n",
      "X_presence shape: torch.Size([46, 56, 83])\n",
      "Y_main shape: torch.Size([46, 8, 56])\n",
      "Y_sub shape: torch.Size([46, 4, 56])\n",
      "mask shape: torch.Size([46, 56])\n",
      "X_numeric shape: torch.Size([46, 56, 58])\n",
      "X_presence shape: torch.Size([46, 56, 83])\n",
      "Y_main shape: torch.Size([46, 8, 56])\n",
      "Y_sub shape: torch.Size([46, 4, 56])\n",
      "mask shape: torch.Size([46, 56])\n",
      "X_numeric shape: torch.Size([69, 56, 58])\n",
      "X_presence shape: torch.Size([69, 56, 83])\n",
      "Y_main shape: torch.Size([69, 8, 56])\n",
      "Y_sub shape: torch.Size([69, 4, 56])\n",
      "mask shape: torch.Size([69, 56])\n",
      "X_numeric shape: torch.Size([62, 56, 58])\n",
      "X_presence shape: torch.Size([62, 56, 83])\n",
      "Y_main shape: torch.Size([62, 8, 56])\n",
      "Y_sub shape: torch.Size([62, 4, 56])\n",
      "mask shape: torch.Size([62, 56])\n",
      "X_numeric shape: torch.Size([42, 56, 58])\n",
      "X_presence shape: torch.Size([42, 56, 83])\n",
      "Y_main shape: torch.Size([42, 8, 56])\n",
      "Y_sub shape: torch.Size([42, 4, 56])\n",
      "mask shape: torch.Size([42, 56])\n",
      "X_numeric shape: torch.Size([49, 56, 58])\n",
      "X_presence shape: torch.Size([49, 56, 83])\n",
      "Y_main shape: torch.Size([49, 8, 56])\n",
      "Y_sub shape: torch.Size([49, 4, 56])\n",
      "mask shape: torch.Size([49, 56])\n",
      "X_numeric shape: torch.Size([36, 56, 58])\n",
      "X_presence shape: torch.Size([36, 56, 83])\n",
      "Y_main shape: torch.Size([36, 8, 56])\n",
      "Y_sub shape: torch.Size([36, 4, 56])\n",
      "mask shape: torch.Size([36, 56])\n",
      "X_numeric shape: torch.Size([42, 56, 58])\n",
      "X_presence shape: torch.Size([42, 56, 83])\n",
      "Y_main shape: torch.Size([42, 8, 56])\n",
      "Y_sub shape: torch.Size([42, 4, 56])\n",
      "mask shape: torch.Size([42, 56])\n",
      "X_numeric shape: torch.Size([25, 56, 58])\n",
      "X_presence shape: torch.Size([25, 56, 83])\n",
      "Y_main shape: torch.Size([25, 8, 56])\n",
      "Y_sub shape: torch.Size([25, 4, 56])\n",
      "mask shape: torch.Size([25, 56])\n",
      "X_numeric shape: torch.Size([19, 56, 58])\n",
      "X_presence shape: torch.Size([19, 56, 83])\n",
      "Y_main shape: torch.Size([19, 8, 56])\n",
      "Y_sub shape: torch.Size([19, 4, 56])\n",
      "mask shape: torch.Size([19, 56])\n",
      "X_numeric shape: torch.Size([34, 56, 58])\n",
      "X_presence shape: torch.Size([34, 56, 83])\n",
      "Y_main shape: torch.Size([34, 8, 56])\n",
      "Y_sub shape: torch.Size([34, 4, 56])\n",
      "mask shape: torch.Size([34, 56])\n",
      "X_numeric shape: torch.Size([31, 56, 58])\n",
      "X_presence shape: torch.Size([31, 56, 83])\n",
      "Y_main shape: torch.Size([31, 8, 56])\n",
      "Y_sub shape: torch.Size([31, 4, 56])\n",
      "mask shape: torch.Size([31, 56])\n",
      "X_numeric shape: torch.Size([18, 56, 58])\n",
      "X_presence shape: torch.Size([18, 56, 83])\n",
      "Y_main shape: torch.Size([18, 8, 56])\n",
      "Y_sub shape: torch.Size([18, 4, 56])\n",
      "mask shape: torch.Size([18, 56])\n",
      "X_numeric shape: torch.Size([17, 56, 58])\n",
      "X_presence shape: torch.Size([17, 56, 83])\n",
      "Y_main shape: torch.Size([17, 8, 56])\n",
      "Y_sub shape: torch.Size([17, 4, 56])\n",
      "mask shape: torch.Size([17, 56])\n",
      "X_numeric shape: torch.Size([38, 56, 58])\n",
      "X_presence shape: torch.Size([38, 56, 83])\n",
      "Y_main shape: torch.Size([38, 8, 56])\n",
      "Y_sub shape: torch.Size([38, 4, 56])\n",
      "mask shape: torch.Size([38, 56])\n",
      "X_numeric shape: torch.Size([20, 56, 58])\n",
      "X_presence shape: torch.Size([20, 56, 83])\n",
      "Y_main shape: torch.Size([20, 8, 56])\n",
      "Y_sub shape: torch.Size([20, 4, 56])\n",
      "mask shape: torch.Size([20, 56])\n",
      "X_numeric shape: torch.Size([5, 56, 58])\n",
      "X_presence shape: torch.Size([5, 56, 83])\n",
      "Y_main shape: torch.Size([5, 8, 56])\n",
      "Y_sub shape: torch.Size([5, 4, 56])\n",
      "mask shape: torch.Size([5, 56])\n",
      "X_numeric shape: torch.Size([23, 56, 58])\n",
      "X_presence shape: torch.Size([23, 56, 83])\n",
      "Y_main shape: torch.Size([23, 8, 56])\n",
      "Y_sub shape: torch.Size([23, 4, 56])\n",
      "mask shape: torch.Size([23, 56])\n",
      "X_numeric shape: torch.Size([26, 56, 58])\n",
      "X_presence shape: torch.Size([26, 56, 83])\n",
      "Y_main shape: torch.Size([26, 8, 56])\n",
      "Y_sub shape: torch.Size([26, 4, 56])\n",
      "mask shape: torch.Size([26, 56])\n",
      "X_numeric shape: torch.Size([16, 56, 58])\n",
      "X_presence shape: torch.Size([16, 56, 83])\n",
      "Y_main shape: torch.Size([16, 8, 56])\n",
      "Y_sub shape: torch.Size([16, 4, 56])\n",
      "mask shape: torch.Size([16, 56])\n",
      "X_numeric shape: torch.Size([11, 56, 58])\n",
      "X_presence shape: torch.Size([11, 56, 83])\n",
      "Y_main shape: torch.Size([11, 8, 56])\n",
      "Y_sub shape: torch.Size([11, 4, 56])\n",
      "mask shape: torch.Size([11, 56])\n",
      "X_numeric shape: torch.Size([9, 56, 58])\n",
      "X_presence shape: torch.Size([9, 56, 83])\n",
      "Y_main shape: torch.Size([9, 8, 56])\n",
      "Y_sub shape: torch.Size([9, 4, 56])\n",
      "mask shape: torch.Size([9, 56])\n",
      "X_numeric shape: torch.Size([13, 56, 58])\n",
      "X_presence shape: torch.Size([13, 56, 83])\n",
      "Y_main shape: torch.Size([13, 8, 56])\n",
      "Y_sub shape: torch.Size([13, 4, 56])\n",
      "mask shape: torch.Size([13, 56])\n",
      "X_numeric shape: torch.Size([13, 56, 58])\n",
      "X_presence shape: torch.Size([13, 56, 83])\n",
      "Y_main shape: torch.Size([13, 8, 56])\n",
      "Y_sub shape: torch.Size([13, 4, 56])\n",
      "mask shape: torch.Size([13, 56])\n",
      "X_numeric shape: torch.Size([3, 56, 58])\n",
      "X_presence shape: torch.Size([3, 56, 83])\n",
      "Y_main shape: torch.Size([3, 8, 56])\n",
      "Y_sub shape: torch.Size([3, 4, 56])\n",
      "mask shape: torch.Size([3, 56])\n",
      "X_numeric shape: torch.Size([11, 56, 58])\n",
      "X_presence shape: torch.Size([11, 56, 83])\n",
      "Y_main shape: torch.Size([11, 8, 56])\n",
      "Y_sub shape: torch.Size([11, 4, 56])\n",
      "mask shape: torch.Size([11, 56])\n",
      "X_numeric shape: torch.Size([10, 56, 58])\n",
      "X_presence shape: torch.Size([10, 56, 83])\n",
      "Y_main shape: torch.Size([10, 8, 56])\n",
      "Y_sub shape: torch.Size([10, 4, 56])\n",
      "mask shape: torch.Size([10, 56])\n",
      "X_numeric shape: torch.Size([9, 56, 58])\n",
      "X_presence shape: torch.Size([9, 56, 83])\n",
      "Y_main shape: torch.Size([9, 8, 56])\n",
      "Y_sub shape: torch.Size([9, 4, 56])\n",
      "mask shape: torch.Size([9, 56])\n",
      "X_numeric shape: torch.Size([6, 56, 58])\n",
      "X_presence shape: torch.Size([6, 56, 83])\n",
      "Y_main shape: torch.Size([6, 8, 56])\n",
      "Y_sub shape: torch.Size([6, 4, 56])\n",
      "mask shape: torch.Size([6, 56])\n",
      "X_numeric shape: torch.Size([6, 56, 58])\n",
      "X_presence shape: torch.Size([6, 56, 83])\n",
      "Y_main shape: torch.Size([6, 8, 56])\n",
      "Y_sub shape: torch.Size([6, 4, 56])\n",
      "mask shape: torch.Size([6, 56])\n",
      "X_numeric shape: torch.Size([15, 56, 58])\n",
      "X_presence shape: torch.Size([15, 56, 83])\n",
      "Y_main shape: torch.Size([15, 8, 56])\n",
      "Y_sub shape: torch.Size([15, 4, 56])\n",
      "mask shape: torch.Size([15, 56])\n",
      "X_numeric shape: torch.Size([11, 56, 58])\n",
      "X_presence shape: torch.Size([11, 56, 83])\n",
      "Y_main shape: torch.Size([11, 8, 56])\n",
      "Y_sub shape: torch.Size([11, 4, 56])\n",
      "mask shape: torch.Size([11, 56])\n",
      "X_numeric shape: torch.Size([7, 56, 58])\n",
      "X_presence shape: torch.Size([7, 56, 83])\n",
      "Y_main shape: torch.Size([7, 8, 56])\n",
      "Y_sub shape: torch.Size([7, 4, 56])\n",
      "mask shape: torch.Size([7, 56])\n",
      "X_numeric shape: torch.Size([9, 56, 58])\n",
      "X_presence shape: torch.Size([9, 56, 83])\n",
      "Y_main shape: torch.Size([9, 8, 56])\n",
      "Y_sub shape: torch.Size([9, 4, 56])\n",
      "mask shape: torch.Size([9, 56])\n",
      "X_numeric shape: torch.Size([14, 56, 58])\n",
      "X_presence shape: torch.Size([14, 56, 83])\n",
      "Y_main shape: torch.Size([14, 8, 56])\n",
      "Y_sub shape: torch.Size([14, 4, 56])\n",
      "mask shape: torch.Size([14, 56])\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=False, drop_last=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=1, shuffle=False, drop_last=True)\n",
    "calibration_dataloader = DataLoader(calibration_dataset, batch_size=1, shuffle=False, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, drop_last=True)\n",
    "\n",
    "for batch in test_dataloader.dataset:\n",
    "    X_numeric, X_presence, Y_main, Y_sub, mask = batch.tensors\n",
    "    print(\"X_numeric shape:\", X_numeric.shape)\n",
    "    print(\"X_presence shape:\", X_presence.shape)\n",
    "    print(\"Y_main shape:\", Y_main.shape)\n",
    "    print(\"Y_sub shape:\", Y_sub.shape)\n",
    "    print(\"mask shape:\", mask.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1988.9763\n"
     ]
    }
   ],
   "source": [
    "model = AKIPredictionModel(hidden_size, embedding_size, num_layers, Embedding_num_layers, Embedding_module, Recurrent_module, seq_len, LN, highway_network,len(train_dataloader.dataset[0].tensors[0][0][0]), len(train_dataloader.dataset[0].tensors[1][0][0]),CB).to(device)\n",
    "model.load_state_dict(torch.load('trial_26_model.pt'))\n",
    "\n",
    "main_datasets, sub_datasets= test(model, test_dataloader) \n",
    "\n",
    "save_path = \"main_dataset_3D_Optuna.pt\"\n",
    "torch.save(main_datasets, save_path)\n",
    "\n",
    "save_path = \"sub_dataset_3D_Optuna.pt\"\n",
    "torch.save(sub_datasets, save_path)\n",
    "\n",
    "main_dataloaders = [DataLoader(dataset, batch_size=1, shuffle=False, drop_last=True) for dataset in main_datasets]\n",
    "sub_dataloaders = [DataLoader(dataset, batch_size=1, shuffle=False, drop_last=True) for dataset in sub_datasets]\n",
    "\n",
    "main_dataloader_6h ,main_dataloader_12h ,main_dataloader_18h ,main_dataloader_24h,main_dataloader_30h ,main_dataloader_36h ,main_dataloader_42h ,main_dataloader_48h = main_dataloaders\n",
    "sub_dataloader_1 ,sub_dataloader_2 ,sub_dataloader_3, sub_dataloader_3D = sub_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1018.3242\n"
     ]
    }
   ],
   "source": [
    "model = AKIPredictionModel(hidden_size, embedding_size, num_layers, Embedding_num_layers, Embedding_module, Recurrent_module, seq_len, LN, highway_network,len(train_dataloader.dataset[0].tensors[0][0][0]), len(train_dataloader.dataset[0].tensors[1][0][0]),CB).to(device)\n",
    "model.load_state_dict(torch.load('trial_26_model.pt'))\n",
    "\n",
    "main_datasets, sub_datasets= test(model, calibration_dataloader) \n",
    "\n",
    "save_path = \"main_dataset_3D_Optuna_calibration.pt\"\n",
    "torch.save(main_datasets, save_path)\n",
    "\n",
    "save_path = \"sub_dataset_3D_Optuna_calibration.pt\"\n",
    "torch.save(sub_datasets, save_path)\n",
    "\n",
    "main_dataloaders = [DataLoader(dataset, batch_size=1, shuffle=False, drop_last=True) for dataset in main_datasets]\n",
    "sub_dataloaders = [DataLoader(dataset, batch_size=1, shuffle=False, drop_last=True) for dataset in sub_datasets]\n",
    "\n",
    "main_dataloader_6h ,main_dataloader_12h ,main_dataloader_18h ,main_dataloader_24h,main_dataloader_30h ,main_dataloader_36h ,main_dataloader_42h ,main_dataloader_48h = main_dataloaders\n",
    "sub_dataloader_1 ,sub_dataloader_2 ,sub_dataloader_3, sub_dataloader_3D = sub_dataloaders"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
